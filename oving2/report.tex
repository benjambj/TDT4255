\documentclass[11pt]{article}

\usepackage{graphicx,amsmath,amssymb,subfigure,url,xspace}
\usepackage[colorlinks=true]{hyperref}
\newcommand{\eg}{e.g.,\xspace}
\newcommand{\bigeg}{E.g.,\xspace}
\newcommand{\etal}{\textit{et~al.\xspace}}
\newcommand{\etc}{etc.\@\xspace}
\newcommand{\ie}{i.e.,\xspace}
\newcommand{\bigie}{I.e.,\xspace}

\title{Exercise 2 - Implementation of a Multicycle Processor}
\author{Benjamin Bj\o rnseth}

\begin{document}
\maketitle

\begin{abstract}
  In this exercise, we were to design and implement a multicycle processor. I
  made a design in which the processor is split into two pieces: the circuitry
  which performs operations on the register file and memory, and a control unit
  which drives the previously mentioned hardware. The control unit ended up
  having to use a larger number of cycles than expected per operation, due to a
  large amount registers being constructed from synthesis of the VHDL. The full
  design performs correctly in a simulated environment, but only partially so on
  the FPGA in which it was physically realized.
\end{abstract}

\section{Introduction}
\label{sec:introduction}
The overall goal of the exercise was to make a multicycle processor
which could be included as a component in a peripheral on an FPGA
board. The way it was to be used once uploaded to the FPGA is shown in
\autoref{fig:communication}. The script, driver program and
communication module were provided, along with several other files
\footnote{The other files were a memory module, a register file, an
  ALU, a top level structural definition, a peripheral interface
  definition and an example testbench.}. Of these, only the
communication module was required to use.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.5]{figures/communication.png}
  \caption{\label{fig:communication} The intended usage of the
    processor. MORE EXPLANATION?}
\end{figure}

In addition to the support files, we were also given a schematic for a
suggested processor architecture. This schematic is depicted in
\autoref{fig:suggestedArchitecture}. We were also given a suggested
instruction word format, shown in \autoref{tab:suggestedFormat}.
\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.4]{figures/suggested_architecture.png}
  \caption{\label{fig:suggestedArchitecture} The suggested
    architecture. Data memory has four input signals. Two of them are
    control signals---read and write. The one coming from the
    instruction register goes to the memory address, while the input
    from the bottom-most register circumventing the ALU goes to the
    data value signal.}
\end{figure}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    {\bf name} & opcode & unused & funct & imm & Rd & Rb & Ra \\ \hline
    {\bf bits} & 31--29 & 28--24 & 23--20 & 19--12 & 11--8 & 7--4 & 3--0 \\ \hline
  \end{tabular}
  \caption{The suggested instruction format. The values of Ra, Rb and Rd are the three top-most signals coming out of the instruction register, respectively. The values in registers Ra and Rb are the inputs to the ALU from top to bottom.}
  \label{tab:suggestedFormat}
\end{table}


Our processor was required to support the following set of instructions:
\begin{itemize}
\item Instructions which use an ALU.
\item A memory-to-register load instruction.
\item A register-to-memory store instruction.
\item An instruction-to-register load immediate instruction.
\item A branch instruction.
\end{itemize}

To make my processor, I decided to use the supplied framework. My
implementation was also based on the suggestions previously mentioned,
with a few slight modifications I will get back to in
\autoref{sec:solution}. The challenge that was left, then, was mainly
to decide upon a cycle partitioning scheme for the execution of the
different types of instructions. I also had to decide on a more
specific instruction set, and adjust the instruction format based on
these decisions.

\section{Solution}
\label{sec:solution}
The design I had wanted to create, is shown in
\autoref{fig:expectedArchitecture}. It is basically the suggested
architecture, with a few alterations. 

For instance, to support the load and store instructions of my
instruction set, I needed to calculate the address. As such, I could
not simply map the immediate value of the instruction to the address
input of the data memory. Instead, it had to go as an input to the
ALU, whose output would have to be connected to the data memory
address signal. Consequently, I had to add a multiplexor in front of
ALU input B, to choose between using either the offset value for load
and store instructions or the register value for ALU instructions. A
multiplexor to choose the function of the ALU was also needed, so that
addition could be chosen when a load or store was to be executed.

Another thing I added was a register in which to store the result of
an ALU calculation. This was needed to make sure that the output was
stable before using it either for memory access or register storage,
which would be the case if the ALU operation was not slower than one
cycle.

The read-enable control signal to the data memory is removed. This was
done because it seemed to serve no purpose - in the memory module that
was handed to us, something is always read, and there is no way to
turn that off. Although there would be merit to such a control signal
in a real processor with real memory blocks, for this exercise I found
it redundant to include both a read and a write signal.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/expected_architecture.png}
  \caption{\label{fig:expectedArchitecture} The architecture I had expected.}
\end{figure}


\subsection{Instruction Set}
\label{subsec:instructionSet}
The instruction set I decided upon is given in
\autoref{tab:instructionSet}. It supports the minimal set of
instructions required. As a branching instruction, I chose to
implement `Branch Not Zero'. 

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|p{190pt}|}
    \hline
    {\bf Pseudo-assembly} & {\bf Semantics} \\ \hline
    ADD/MOV/AND r{\em D}, r{\em A}, r{\em B} &  Performs the given operation on the values in register number {\em A} and {\em B}, and stores the result in register number {\em D}. \\ \hline
    LDI r{\em D} {\em value} & Stores {\em value} in register number {\em D}. \\ \hline
    LD r{\em D}, {\em offset}(r{\em A}) & Loads the value located at memory address $offset + value_{rA}$ into register number {\em D} \\ \hline
    ST r{\em B}, {\em offset}(r{\em A}) & Stores the value in register number {\em B} at memory address $offset + value_{rA}$. \\ \hline
    BNZ {\em address} & If the previous instruction did not set the status register of the ALU to zero, instruction fetching will continue from the content at instruction memory address {\em address}. Otherwise, instruction fetching will resume as if no instruction had been executed. \\ \hline
  \end{tabular}
  \caption{The supported instruction set.}
  \label{tab:instructionSet}
\end{table}

\subsection{Instruction Format}
\label{subsec:instructionFormat}
My instruction format is given in
\autoref{tab:myInstructionFormat}. It is pretty similar to the
suggested one---the only difference is that there are no unused bits:
the func field is moved left, and the immediate field is extended. The
reason for this was that I thought the processor had access to 32 KiB
of byte-adressable memory, which requires fifteen bits to be fully
addressable. As each instruction is four bytes, a thirteen bit
immediate field would be able to be used as the address for {\em BNZ}
to access the full instruction memory if shifted left twice. These
assumptions about memory were not correct, though, and no such benefit
could be harvested. The immediate is kept this large anyway, however,
so that values from a larger interval can be used for the {\em Load
  Immediate} instruction. For the {\em BNZ} instruction, the eight
least significant bits of the immediate is used as an absolute jump
address.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    {\bf name} & opcode & func & immediate & rD & rB & rA \\ \hline
    {\bf bits} & 31--29 & 28--25 & 24--12 & 11--8 & 7--4 & 3--0 \\ \hline
  \end{tabular}
  \caption{My instruction format}
  \label{tab:myInstructionFormat}
\end{table}

The relation between the opcode and function fields and the operation
performed is given in \autoref{tab:opcodeMapping} and
\autoref{tab:funcMapping}. As for the other instruction fields, their
binary value determine what they represent.

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|p{50pt}|}
    \hline
    {\bf Opcode} & {\bf Function field} & {\bf Instruction performed} \\ \hline
    100 & XXXX & Branch Not Zero \\ \hline
    011 & XXXX & Store \\ \hline
    010 & XXXX & Load \\ \hline
    001 & XXXX & Load immediate \\ \hline
    000 & \multicolumn{2}{|p{70pt}|}{Mapping given in \autoref{tab:funcMapping}} \\ \hline
  \end{tabular}
  \caption{Mapping between opcode and instruction performed.}
  \label{tab:opcodeMapping}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|p{50pt}|}
    \hline
    {\bf Function field} & {\bf Instruction performed} \\ \hline
    0000 & Move \\ \hline
    0001 & And \\ \hline
    0111 & Add \\ \hline
  \end{tabular}
  \caption{Mapping between function field and the instruction performed.}
  \label{tab:funcMapping}
\end{table}


\subsection{The Processor}
\label{subsec:processor}
The schematic for my processor architecture is shown in
\autoref{fig:myProcessorArchitecture}. As can be seen by comparing it
with the architecture shown in \autoref{sec:solution}, this is not
exactly what I had planned on making. Specifically, there are quite
many more registers than I had wanted. The reason for this is that I
had a lot of clocked processes in my VHDL code to implement the
registers I wanted, while at the same time there existed other clocked
processes for signals going out of the processor and out of the
control unit\footnote{The clocked process for signals in the processor
  interface was needed in order to only start and stop the processor
  on a new cycle. The registers going out of the control unit makes
  sure that the control signals are stable.}. Consequently, signals
took in some cases longer than intended to propagate through the
system. In some situations the problem was solved by adding wires past
registers, as is the case for the ALU output going to the data memory
address. Another easier solution to this problem was to adjust the
states of the control unit, the consequences of which are described in
\autoref{subsec:controlunit}.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/final_architecture.png}
  \caption{\label{fig:myProcessorArchitecture} The actual architecture of my implementation.}
\end{figure}


The program counter is a 32-bit wide register, which holds the address
in memory from where the next instruction is to be fetched. As the
memory modules provided are word-adressable, it is automatically
incremented by one at the end of each instruction execution so that an
instruction can be fetched from the next address in memory. 

In the case of a branch instruction, however, we want to be able to
jump in case a branch is taken.  Thus, the input to the register is
guarded by a multiplexor, which chooses either the next instruction or
the branch target based on whichever is deemed appropriate by the
control unit. The control unit also controls writing to the program
counter with a write-enable signal, so that it is not continuously
updated.

The incrementing is done with a separate adder, rather than using the
ALU. The reason is that using the ALU would complicate both the
control unit logic and the design by adding more muxes to both ALU
inputs and function selection.

As described in \autoref{subsec:instructionSet}, the {\em Store}
instruction takes its value to store from register number {\em B}. The
reason for this is that the register file that was handed to us has
support for reading two registers and writing one register. When
performing the {\em Store} instruction, we want to use the ALU for
adding together the value in register number {\em A} and $offset$, and
as such the multiplexer in front of ALU input {\em B} will choose the
immediate value. However, if we circumvent the multiplexer by adding a
wire from the output of register number {\em B} directly to the data
memory value input, we can use the output from register B
anyways. Organizing it in this fashion makes register file access more
regular, as the same instruction fields can be directly mapped to
their register numbers without any cluttering access logic. This makes
the design simpler, and is thus a favorable solution.

\subsection{The Control Unit}
\label{subsec:controlunit}
My control unit operates as described in
\autoref{tab:controlUnitStates}. Due to the extra number of registers,
a lot of cycles are used to wait for registers to update. Notice that
the control unit also has registers for its every control signal,
which means that asserting a control signal in a cycle means that the
processor doesn't see it until the cycle after that. In the case where
the control signal goes to control memory, there will be another clock
cycle of delay due to the register in front of the memory. This means,
for instance, that a store instruction only actually updates the data
memory at the beginning of the next instruction execution phase.
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|p{50pt}|p{50pt}|p{50pt}|p{50pt}|p{50pt}|}
    \hline
    {\bf Instruction} & ALU-instruction & Load immediate & Load & Store & Branch not zero \\ \hline
    {\bf Cycle 1} & \multicolumn{5}{|p{200pt}|}{Update the value on the instruction memory address bus to the current value of the program counter} \\ \hline
    {\bf Cycle 2} & \multicolumn{5}{|p{200pt}|}{Wait for the requested value to be read from the instruction memory.} \\ \hline
    {\bf Cycle 3} & Select func field for ALU. Select register value for input to B. & Wait for immediate to load. & Select ``add'' function to ALU. Select offset value for input to B. & Select ``add'' function to ALU. Select offset value for input to B. & Select PC input based on the value in the status register. Wait for immediate register to load. \\ \hline
    {\bf Cycle 4} & Wait for register B to get loaded & Select immediate value as input to register file. Select incremented PC as the new PC value. Assert regfile and PC write-enable.  & Wait for immediate to get loaded. & Wait for register B to get loaded & Assert write to PC.  \\ \hline
    {\bf Cycle 5} & Execute operation. Select ALu-output as register file input. & Deassert all write-enables. & Wait for register B to get loaded. & Assert control unit dmem write-enable. Select incremented PC as the new PC value. Assert PC write-enable. & Deassert all write-enables. \\ \hline
  \end{tabular}
  \caption{The states of the control unit, part 1.}
  \label{tab:controlUnitStates}
\end{table}

\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|p{50pt}|p{50pt}|p{50pt}|p{50pt}|p{50pt}|}
    \hline
    {\bf Cycle 6} & Assert regfile, status, alu-out and program counter write-enable. Select incremented PC as the new PC value. &  & Select memory as input to register file. Wait for dmem address to propagate.  & Deassert all write-enables.  & \\ \hline
    {\bf Cycle 7} & Deassert all write-enables. &  & Select incremented PC as the new PC value. Assert regfile and program counter write-enable. &  &  \\ \hline
    {\bf Cycle 8} &  &  & Deassert all write-enables. &  &  \\ \hline
  \end{tabular}
  \caption{Control unit states cont.}
  \label{tab:controlUnitStatesCont}
\end{table}

\section{Results}
\label{sec:results}
To test that the processer implementation was working as it was
supposed to, I performed functionality testing in ModelSim, as well as
tests of the implementation uploaded to the FPGA.
\subsection{Functionality Tests in Modelsim}
\label{subsec:functestsim}
I created two different test benches to verify the correctness of my
implementation---one for the processor alone, and one of the entire
peripheral. Both of them gave positive results. However, I will only
reproduce here the results of the tests of the entire peripheral, as
these should be extensive enough to be representable.

The contents of my testbench can be found in the {\em
  toplevel\_tb.vhd} file of my project delivery. In the testbench, the
toplevel and communication module is tested first. Then, the
instruction memory is loaded with some instructions, before the
processor is set to run. The instructions are split into three
parts. First, some simple single-instruction tests are
performed. Then, a loop which stores the values 1 to 10 in the
respective memory addresses is executed. Finally, a loop which loads
these values from memory and accumulates them in a register is
run. The result is then stored at memory address 0xFF.

Below follows some screenshots of waveforms captured in ModelSim,
showing that the results from the test bench are positive.

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_2_load_immediate_cropped.png}
  \caption{\label{fig:ldi} Performing a load immediate operation,
    storing the value 1 in register 1. As can be seen, the result is
    properly stored in the register file.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_3_store_cropped.png}
  \caption{\label{fig:ldi} Performing a store operation. This
    screenshot shows that the value is properly stored in the data
    memory module.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_4_load_cropped.png}
  \caption{\label{fig:ldi} Performing a load from memory. The contents
    of memory address zero is loaded into register five, as was
    intenteded.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_5_alu_and_cropped.png}
  \caption{\label{fig:ldi} An ALU operation of type bitwise AND is
    performed. As shown here, it is stored in the register specified.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_6_bnz_not_taken_cropped_2.png}
  \caption{\label{fig:ldi} A Branch Not Zero instruction. As the value
    of {\em status} implies that the previous result was zero, the
    branch is not taken. This can be seen on the next value of
    imem\_addr, which is just an incremented version of the previous
    value.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_7_store_loop_cropped.png}
  \caption{\label{fig:ldi} Here we are at the end of the storage loop
    described at the top of this section. As we can see, every memory
    location gets updated with the correct value.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_8_load_add_loop_cropped.png}
  \caption{\label{fig:ldi} Here we are close to the end of the load
    and accumulation loop. The counting register, register $2$, has a
    value of $1$, being decremented and reaching $0$ at the end of this
    iteration. Register $5$ contains the value at the memory address of
    register $2$, while register $4$ keeps the running total. Register $3$
    contains the value $-1$.}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[scale=0.35]{figures/Func_test_9_store_at_offset_cropped.png}
  \caption{\label{fig:ldi} The running total from the previous loop is
    properly stored at memory location 0xFF.}
\end{figure}

\subsection{Timing Tests in Modelsim}
\label{subsec:timingtestsim}
I was unable to get timing simulations to run in ModelSim. I do, however, have the results from timing analysis performed during synthesis of both the peripheral alone as well as the entire embedded system. The only thing I have here is place and route telling me that there is no trouble - max delay around 10ns, max clock almost 110 MHz.

\subsection{Functionality Tests on the FPGA}
\label{subsec:functestfpga}
To verify the functionality of my processor once uploaded on the FPGA,
I used the python script provided to load the instruction memory with
the content of the file {\em testoutput}, whose pseudo-assembly can be
seen in the file {\em testassembly.s}. I then sent a command to start
the processor, followed by a command to stop it. I then made a dump of
the data memory using the python script, to see what was contained
there. Although the values at addresses 1 to 10 were 1 to 10, as
expected, the values at addresses 0xb--0xd were the hexadecimal values
of the instruction that should've been in instruction memory at those
locations. The value at address 0xff was 0x37 which equals 55, and was
as expected. When starting and stopping the processor again, taking a
new dump yielded what should have been the contents of the instruction
memory. 

I then tried clearing the data memory by setting it all to zero,
uploading the program again to instruction memory, and taking a new
data memory dump. This yielded the contents of the instruction
memory. As there are no such problems when writing to instruction
memory in the simulation, I suspect that this is a problem with the
definition of either my embedded system project or the inclusion of
the peripheral in it. The processor design can be ruled out as the
cause, at least, seeing how it is not active during the writing and
reading of data and instruction memory. Any further than this I was
unfortunately unable to figure out.

\section{Discussion}
\label{sec:discussion}
There are several shortcomings in my processor design, the most
obvious of which is probably the rather extensive amount of states in
my control unit. As the clock cycle is set at a given frequency for
the board on which it was to be implemented, the clock frequency will
not increase by having more finer grained cycle stages. Thus, the
design gets slower with the amount of cycles it takes to execute an
instruction. As such, it would be beneficial if this could be reduced. 

One way to do this might be to adopt the convention that writes occur
on the rising edge of the clock, and reads on the falling edge. With
this scheme, instead of waiting a cycle to get the updated value of a
register we would be able to get it in the middle of the current
cycle. If the work we wanted to do on this value could be performed in
half a clock cycle's time, then this would be a candidate for
minimizing the number of control unit states worth considering.

Another possibility would be to try and remove some registers. The
ones at the output of the control unit, for instance, are not needed,
but are simply a side effect of using the clock for the internal state
of the control unit. They are removable in theory, and with a little
bit of tinkering they might be removable in practice as well. As was
mentioned in \autoref{subsec:processor}, the registers going out of
the processor and out to the memory modules were also unforeseen
hindrances. These were the result of the processor-enable and reset
signals, however, and thus they serve a more valid purpose. Although
harder to remove, it might be doable if one could make sure that the
processor did not actually start until the next cycle after having
received a logical high processor-enable signal, but stopped
immediately upon request.

Another possible optimization in the current design is the
agglomeration of redundant states into one. For instance, at the end
of every instruction execution sequence there is a state which
deasserts every write-enable. If one reads the control unit source
code, one can see that the state was primarily introduced to give time
for the PC write-enable signal to propagate out of the control unit
and into the processor, at a time where the cause of this delay was
not known. If one just asserts and deasserts this signal one cycle
earlier, it should reach the program counter register at the expected
time. As such, the synchronization state at the end of the execution
should be removable.
\newline
Optimizations could also be made with the instruction format. To allow
for even more bits in the immediate, supporting even immediate values
from an even larger range to be loaded into a register, one could
shrink the opcode and function bits. As there are only seven
instructions\footnote{BNZ, LD, ST, LDI and three ALU operations.}, you
only need three bits to specify which operation you're interested
in. This would not necessarily complicate instruction decoding
either. An example mapping between opcode and function fields and the
corresponding instruction performed is shown in
\autoref{tab:alternativeFormat}. 
\begin{table}[htbp]
  \centering
  \begin{tabular}{|c|c|}
    \hline
    {\bf Field value} & {\bf Instruction performed} \\ \hline
    111 & Branch not zero \\ \hline
    110 & Store \\ \hline
    101 & Load \\ \hline
    100 & Load immediate \\ \hline
    011 & Add \\ \hline
    010 & And \\ \hline
    001 & Move \\ \hline
    000 & Unused \\ \hline
  \end{tabular}
  \caption{An alternative mapping between opcode fields and instruction performed.}
  \label{tab:alternativeFormat}
\end{table}
If the ALU is edited so that the
function code for an operation are the same as the two least
significant bits of the corresponding opcode, then instructions could
be executed about as simply as they are at present. Simply map the two
least significant bits of the opcode to the function field, and have
the multiplexor guarding the ALU function input choose either this
value or ``add'' based on the value of the most significant bit of the
opcode. 

With this optimization, 17 bits are now available for use as the
immediate value. As was previously discussed, we gain the luxury of
allowing larger values of immediates to be loaded into registers. This
gain comes at the price of having a less extensible processor. There
would only be room for adding one extra ALU instruction---anything
else would have to chew into the immediate value field and break
backwards compatibility. One must thus predict what amount of
instructions the processor and ALU could benefit from supporting, and
make the opcode and function fields at least large enough to hold this
estimate. 

\newline

A simple redundancy present in the current design is the multiplexor
in front of the function selection input of the ALU. One could remove
this completely by editing the opcode mapping described in
\autoref{tab:opcodeMapping}. Instead of having the ALU function field
assume don't-care values for the load and store instructions, they
could have the function field required for an add. We could then
simply map the function field from the instruction register to the
ALU, saving the space and cost of a multiplexer. This optimization
does not seamlessly integrate with the one previously described, as
their is no separate function field. If the unused opcode/function
value would also map to the ADD function of the ALU, this would be
doable---if the two least significant bits of the load and store
opcode was the same as the ones used for add instructions, then a
direct mapping between these bits and the function field would
work. It would leave no room whatsoever for extensions to the
processor instruction set, though.

\newline

The potential benefits of a multicycle design are twofold: Space
savings by reusing components in different cycles, and time savings by
having instruction execution latency be as short as possible for each
instruction. 

In my design, the space savings part is by and large
ignored. The two use cases for this in my processor would be reusing
the ALU for calculating an incremented program counter value, and
using a single memory module for both instructions and data. As was
discussed in \autoref{subsec:processor}, reusing the ALU would hardly
be a gain, considering what would have to be added in place of the
separate incrementer. Using a single memory would be plausible, but
then we would cut our already scarce memory resources in half. As
such, I saw no need to do this. 

The time savings, however, is heavily invested into. Although I have
just discussed at length how my processor is not exactly blazingly
fast, it does optimize quite well for individual instructions. The
load-immediate and branch-not-zero instructions, for instance, execute
in five cycle, which is just $5/8 = 62.5\%$ of the time required for
the load instruction. Seeing how the majority of the optimizations
previously discussed are of a global nature, time savings are
certainly possible in this design compared to a single-cycle one.

\section{Conclusion}
\label{sec:conclusion}
In this exercise, I designed and implemented a multicycle processor. A
lot of issues with the implementation were discovered only after
actually having finished it, and as such there are many optimizations
to the final design left which could have been made. Regardless, the
design itself was not exposed as having any major drawbacks, and
applying simple workarounds to fix the implementation issues still
left a processor which benefits in individual instruction execution
time from a multicycle design. The processor did not function properly
as a peripheral uploaded to an FPGA board. This is likely to be caused
by a faulty project setup, however, and does probably not have to do
with a flaw in the processor design.

\bibliographystyle{plain}
\bibliography{literature.bib}

\end{document}

%We were given an implementation of a suggested structure of
%this peripheral. 

%Amongst these handouts, the only part we were
%required to use was a communication module. This module had the
%ability to read and write to memory as well as start the
%processor. The communication module would operate based on the values
%of some registers, set by a C driver program. Once on the FPGA, we
%could run the processor by first using a python script to send
%instructions across a USB connection. a C driver program would listen
%to incoming instructions pass instructions

%We weren
%handed several support files, amongst them VHDL implementations of
%components such as memory, a register file, an ALU, a communication
%module and a top level component used to glue together the different
%parts of the peripheral. The communication module could initialize and
%read memory as well as start the processor, and we were required to
%use it. This component, together with a C driver which was also in the
%handouts, was used for controlling the processor once uploaded on the
%FPGA.

%Instruction format could get even more bits for immediate. 
%Consequences of architecture not turning out the way I wanted.
%Control Unit options---currently slow. 
%   e.g. write rising-edge read falling-edge, yields stable input for CU which might remove need for clock?
%   other ways to circumvent registers.
%   some states are actually unnecessary - update PC could in some cases be included in other states.
%Simplifications:
%    The multiplexor for choosing ALU function is strictly unnecessary - you can just have load and store instructions translate into ones which have the code for 'add' in their funct field.
%FPGA test results failure.
%To what degree do I utilize the benefits of a multicycle design?
